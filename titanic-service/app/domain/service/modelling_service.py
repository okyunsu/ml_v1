import numpy as np
from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, cross_val_score, StratifiedKFold
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from app.domain.model.data_schema import DataSchema
from scipy.stats import reciprocal


class ModelingService:
    """
    ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ë¥¼ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ (íŒ©í† ë¦¬ íŒ¨í„´ ì ìš©)
    """

    @staticmethod
    def create_k_fold(this):
        """K-Fold ê°ì²´ ìƒì„±"""
        X_train = this.train
        y_train = this.label
        k_fold = KFold(n_splits=10, shuffle=True, random_state=0)
        return X_train, y_train, k_fold

    @staticmethod
    def create_random_variable(this):
        """ëª¨ë¸ë³„ ì •í™•ë„ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
        return {
            'logistic_regression': [],
            'decision_tree': [],
            'random_forest': [],
            'naive_bayes': [],
            'knn': [],
            'svm': []
        }

    @staticmethod
    def create_model(model_name):
        """íŒ©í† ë¦¬ íŒ¨í„´ìœ¼ë¡œ ëª¨ë¸ ê°ì²´ ìƒì„±"""
        model_factory = {
            'ëœë¤í¬ë ˆìŠ¤íŠ¸': RandomForestClassifier(n_estimators=100, random_state=0),
            'ë‚˜ì´ë¸Œë² ì´ì¦ˆ': GaussianNB(),
            'ë² ì´ìŠ¤ë¼ì¸(ë¡œì§€ìŠ¤í‹± íšŒê·€)': LogisticRegression(max_iter=3000, class_weight='balanced'),
            'ê²°ì •íŠ¸ë¦¬': DecisionTreeClassifier(random_state=0),
            'KNN': KNeighborsClassifier(n_neighbors=5),
            'SVM': SVC(kernel='rbf', C=10, gamma='scale', random_state=0, class_weight='balanced')
        }

        if model_name not in model_factory:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ëª…: {model_name}")
        
        scaler_needed = (model_name == 'SVM')  # SVMì€ ë°˜ë“œì‹œ ìŠ¤ì¼€ì¼ë§
        return model_factory[model_name], scaler_needed

    @staticmethod
    def accuracy_by_model(this, model_name):
        """ì£¼ì–´ì§„ ëª¨ë¸ëª…ìœ¼ë¡œ êµì°¨ ê²€ì¦ ì •í™•ë„ ê³„ì‚°"""
        X_train, y_train, k_fold = ModelingService.create_k_fold(this)
        model, scaler_needed = ModelingService.create_model(model_name)

        if scaler_needed:
            scaler = StandardScaler()
            X_train = scaler.fit_transform(X_train)

        scores = cross_val_score(model, X_train, y_train, cv=k_fold, scoring='accuracy')
        print(f"[{model_name}] ê° í´ë“œ ì •í™•ë„: {scores}")
        print(f"[{model_name}] í‰ê·  ì •í™•ë„: {scores.mean():.4f}, í‘œì¤€í¸ì°¨: {scores.std():.4f}")
        return scores.mean()

    # ì•„ë˜ ê¸°ì¡´ ë°©ì‹ì€ ê·¸ëŒ€ë¡œ ë‘ì–´ Controller í˜¸í™˜ì„± ìœ ì§€

    @staticmethod
    def accuracy_by_logistic_regression(this):
        return ModelingService.accuracy_by_model(this, 'ë² ì´ìŠ¤ë¼ì¸(ë¡œì§€ìŠ¤í‹± íšŒê·€)')

    @staticmethod
    def accuracy_by_dtree(this):
        return ModelingService.accuracy_by_model(this, 'ê²°ì •íŠ¸ë¦¬')

    @staticmethod
    def accuracy_by_random_forest(this):
        return ModelingService.accuracy_by_model(this, 'ëœë¤í¬ë ˆìŠ¤íŠ¸')

    @staticmethod
    def accuracy_by_naive_bayes(this):
        return ModelingService.accuracy_by_model(this, 'ë‚˜ì´ë¸Œë² ì´ì¦ˆ')

    @staticmethod
    def accuracy_by_knn(this):
        return ModelingService.accuracy_by_model(this, 'KNN')

    @staticmethod
    def accuracy_by_svm(this):
        return ModelingService.accuracy_by_model(this, 'SVM')

    @staticmethod
    def predict_with_model(this, model_name):
        """ìµœì  ëª¨ë¸ë¡œ ì˜ˆì¸¡"""
        model, scaler_needed = ModelingService.create_model(model_name)

        if scaler_needed:
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(this.train)
            X_test_scaled = scaler.transform(this.test)
            model.fit(X_train_scaled, this.label)
            return model.predict(X_test_scaled)
        else:
            model.fit(this.train, this.label)
            return model.predict(this.test)
        

    @staticmethod
    def predict_with_voting(this):
        """ëœë¤í¬ë ˆìŠ¤íŠ¸ + SVM Voting ì•™ìƒë¸”ë¡œ ì˜ˆì¸¡"""
        X_train = this.train
        y_train = this.label
        X_test = this.test

        # ìŠ¤ì¼€ì¼ë§ì€ SVMë§Œ í•„ìš”í•˜ë¯€ë¡œ íŒŒì´í”„ë¼ì¸ ìƒì„±
        svm_pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('svm', SVC(
                kernel='rbf', 
                C=10, 
                gamma='scale', 
                probability=True,  # Soft votingì„ ìœ„í•´ í•„ìš”
                random_state=0
            ))
        ])

        rf = RandomForestClassifier(
            n_estimators=100,
            random_state=0
        )

        # VotingClassifier ìƒì„± (Soft Voting)
        voting_clf = VotingClassifier(
            estimators=[
                ('rf', rf),
                ('svm', svm_pipeline)
            ],
            voting='soft'
        )

        # í•™ìŠµ
        voting_clf.fit(X_train, y_train)

        # ì˜ˆì¸¡
        predictions = voting_clf.predict(X_test)

        return predictions


    @staticmethod
    def tune_random_forest(this):
        """ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"""
        X_train = this.train
        y_train = this.label

        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
        param_grid = {
            'n_estimators': [100, 300, 500],
            'max_depth': [5, 10, 20, None],
            'min_samples_split': [2, 5, 10]
        }

        rf = RandomForestClassifier(random_state=0)

        grid_search = GridSearchCV(
            rf,
            param_grid,
            cv=5,              # 5-Fold êµì°¨ê²€ì¦
            scoring='accuracy', # ì •í™•ë„ ê¸°ì¤€
            n_jobs=-1,          # CPU ëª¨ë‘ ì‚¬ìš©
            verbose=2           # ì§„í–‰ìƒí™© ë³´ì—¬ì¤Œ
        )

        # í•™ìŠµ
        grid_search.fit(X_train, y_train)

        print(f"ğŸ† ìµœì  íŒŒë¼ë¯¸í„°: {grid_search.best_params_}")
        print(f"âœ… ìµœì  êµì°¨ê²€ì¦ ì •í™•ë„: {grid_search.best_score_:.4f}")

        # ìµœì  ëª¨ë¸ ë°˜í™˜
        return grid_search.best_estimator_
    
    @staticmethod
    def tune_svm(this):
        """SVM ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"""
        X_train = this.train
        y_train = this.label

        # íŒŒì´í”„ë¼ì¸: ìŠ¤ì¼€ì¼ë§ + SVM
        pipe = Pipeline([
            ('scaler', StandardScaler()),
            ('svc', SVC(probability=True, random_state=0))
        ])

        # íƒìƒ‰í•  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê³µê°„
        param_distributions = {
            'svc__C': reciprocal(1e-2, 1e2),  # 0.01 ~ 100 ì‚¬ì´ ë¡œê·¸ ë¶„í¬
            'svc__gamma': reciprocal(1e-4, 1e-1)  # 0.0001 ~ 0.1 ì‚¬ì´ ë¡œê·¸ ë¶„í¬
        }

        random_search = RandomizedSearchCV(
            pipe,
            param_distributions,
            n_iter=30,       # 30íšŒ ìƒ˜í”Œë§
            cv=5,            # 5-Fold êµì°¨ê²€ì¦
            scoring='accuracy',
            n_jobs=-1,
            random_state=0,
            verbose=2
        )

        # í•™ìŠµ
        random_search.fit(X_train, y_train)

        print(f"ğŸ† ìµœì  íŒŒë¼ë¯¸í„°: {random_search.best_params_}")
        print(f"âœ… ìµœì  êµì°¨ê²€ì¦ ì •í™•ë„: {random_search.best_score_:.4f}")

        # ìµœì  ëª¨ë¸ ë°˜í™˜
        return random_search.best_estimator_
    
    