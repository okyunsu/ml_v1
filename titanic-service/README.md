# 타이타닉 생존자 예측을 위한 머신러닝 알고리즘 분석

이 문서는 타이타닉 생존자 예측 모델에 적용된, 다양한 머신러닝 알고리즘의 이론적 배경과 실제 데이터에 적용했을 때의 결과를 분석합니다. 이는 분류 문제에 사용되는 주요 알고리즘의 특성과 성능을 이해하는 데 도움이 될 것입니다.

## 데이터셋 특성

타이타닉 데이터셋은 다음과 같은 특성을 가지고 있습니다:

- **범주형 특성**: 성별(Sex), 승선 항구(Embarked), 객실 등급(Pclass)
- **연속형 특성**: 나이(Age), 요금(Fare)
- **이름에서 추출한 특성**: 타이틀(Title) - Mr, Ms, Mrs, Master 등
- **파생 특성**: 나이 그룹(AgeGroup), 요금 그룹(FareGroup)
- **타겟 변수**: 생존 여부(Survived) - 0(사망) 또는 1(생존)

이 데이터는 클래스 불균형이 있으며(생존자 약 38%), 결측치(특히 나이, 객실)가 존재합니다. 전처리 과정을 통해 결측치를 처리하고 범주형 변수를 인코딩했습니다.

## 실험 결과 요약

여러 알고리즘을 비교한 결과, 다음과 같은 정확도를 얻었습니다:

| 알고리즘 | 정확도 | 베이스라인 대비 |
|---------|-------|--------------|
| 랜덤포레스트 | 0.7969 | +0.0292 |
| 나이브베이즈 | 0.7722 | +0.0045 |
| 로지스틱 회귀(베이스라인) | 0.7677 | --- |
| 결정트리 | 0.7464 | -0.0213 |
| SVM | 0.6162 | -0.1515 |
| KNN | 0.5815 | -0.1862 |

이제 각 알고리즘의 작동 원리와 타이타닉 데이터셋에서의 성능에 대해 자세히 살펴보겠습니다.

## 로지스틱 회귀

### 이론적 배경

로지스틱 회귀는 선형 회귀의 확장으로, 이진 분류 문제에 적합한 알고리즘입니다. 선형 함수에 시그모이드 함수(로지스틱 함수)를 적용하여 0과 1 사이의 확률값을 출력합니다.

$$P(Y=1|X) = \frac{1}{1 + e^{-(β_0 + β_1X_1 + β_2X_2 + ... + β_nX_n)}}$$

- 각 $β$는 해당 특성의 회귀 계수
- 출력값이 0.5를 초과하면 클래스 1로, 그렇지 않으면 클래스 0으로 예측

### 타이타닉 데이터셋에 적용

로지스틱 회귀는 타이타닉 생존 예측에서 76.77%의 정확도를 보였습니다. 이 모델은 특히 다음 특성들의 관계를 잘 포착했습니다:

- **성별(Gender)**: 여성이 생존할 확률이 높음
- **객실 등급(Pclass)**: 상위 등급(1등급) 승객의 생존률이 높음
- **나이(AgeGroup)**: 어린이의 생존률이 높음

**구현 세부사항**:
- 표준화(StandardScaler)로 특성 스케일 조정
- class_weight='balanced'로 클래스 불균형 처리
- 5-겹 교차 검증(StratifiedKFold) 사용

### 장점
- 해석이 용이함 (각 특성의 계수가 생존 확률에 미치는 영향을 직접 해석 가능)
- 계산 효율성이 높음
- 과적합 위험이 낮음
- 확률 출력을 직접 사용 가능

### 단점
- 비선형 관계를 직접 모델링하지 못함
- 특성간 상호작용을 자동으로 포착하지 못함

## KNN (K-Nearest Neighbors)

### 이론적 배경

K-최근접 이웃 알고리즘은 새로운 데이터 포인트의 클래스를 예측할 때 특성 공간에서 가장 가까운 K개의 학습 데이터 포인트의 다수결로 결정합니다.

1. 거리 계산: 유클리드 거리, 맨해튼 거리 등을 사용
   $$d(x, y) = \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}$$ (유클리드 거리)
   
2. K개의 가장 가까운 이웃 찾기
3. 다수결 투표로 클래스 결정

### 타이타닉 데이터셋에 적용

KNN은 타이타닉 데이터셋에서 58.15%의 정확도로 가장 낮은 성능을 보였습니다. 이는 다음과 같은 이유 때문입니다:

- **차원의 저주**: 여러 특성이 있을 때 거리 계산의 효율성이 떨어짐
- **특성 스케일**: 특성들의 스케일이 다르면 거리 계산에 왜곡이 발생
- **데이터 분포**: 타이타닉 데이터는 범주형 변수가 많고, 이산적인 분포를 가짐

**구현 세부사항**:
- K=5 (기본값 사용)
- 10-겹 교차 검증 수행

### 장점
- 가정이 거의 없는 비모수적 모델
- 직관적이고 이해하기 쉬움
- 새로운 데이터에 즉시 적응 가능(게으른 학습)

### 단점
- 차원이 증가할수록 성능 저하
- 계산 비용이 높음(예측 시 전체 학습 데이터와 거리 계산 필요)
- 범주형 특성이 많은 데이터에 적합하지 않음
- 최적의 K 값 선정이 어려움

## 나이브베이즈

### 이론적 배경

나이브베이즈는 베이즈 정리를 기반으로 하며, 모든 특성이 서로 독립적이라는 '나이브한' 가정하에 작동합니다.

$$P(y|x_1,...,x_n) = \frac{P(y) \prod_{i=1}^{n} P(x_i|y)}{P(x_1,...,x_n)}$$

여기서:
- $P(y|x_1,...,x_n)$: 특성 $x_1,...,x_n$가 주어졌을 때 클래스 $y$의 확률
- $P(y)$: 클래스 $y$의 사전 확률
- $P(x_i|y)$: 클래스 $y$일 때 특성 $x_i$의 조건부 확률
- $P(x_1,...,x_n)$: 특성의 확률(일정하므로 비교 시 무시 가능)

### 타이타닉 데이터셋에 적용

나이브베이즈는 77.22%의 정확도로 로지스틱 회귀보다 약간 좋은 성능을 보였습니다. 타이타닉 데이터셋에서:

- **독립성 가정이 부분적으로 유효**: 성별, 객실 등급, 나이는 어느 정도 독립적으로 생존에 영향
- **확률 기반 접근**: 생존/사망과 각 특성 간의 확률적 관계를 학습
- **GaussianNB 사용**: 연속형 특성(나이, 요금 등)에 적합

**구현 세부사항**:
- GaussianNB 모델 사용(연속형 변수에 가우시안 분포 가정)
- 10-겹 교차 검증 수행

### 장점
- 계산이 빠르고 효율적
- 적은 양의 훈련 데이터로도 잘 작동
- 확률 출력을 직접 사용 가능
- 고차원 데이터에서도 안정적

### 단점
- 특성 간 독립성 가정이 현실에서는 종종 위배됨
- 학습 데이터에서 보지 못한 특성 값에 대해 0 확률 문제 발생 가능(스무딩으로 완화)

## 결정트리

### 이론적 배경

결정트리는 데이터를 특성 값에 따라 재귀적으로 분할하여 트리 구조를 형성하는 알고리즘입니다. 각 내부 노드는 특성에 대한 테스트를 나타내고, 각 분기는 테스트 결과를, 각 리프 노드는 클래스 레이블을 나타냅니다.

분할 기준:
- **지니 불순도(Gini Impurity)**: $1 - \sum_{i=1}^{J} p_i^2$
- **엔트로피(Entropy)**: $-\sum_{i=1}^{J} p_i \log_2(p_i)$

여기서 $p_i$는 노드에서 클래스 i의 비율입니다.

### 타이타닉 데이터셋에 적용

결정트리는 74.64%의 정확도를 보였습니다. 이는 로지스틱 회귀보다 약간 낮지만, 트리는 다음과 같은 인사이트를 제공했습니다:

- **첫 번째 분할**: 성별(Gender)이 가장 중요한 특성으로 선택됨
- **두 번째 분할**: 객실 등급(Pclass)
- **추가 분할**: 여성의 경우 요금(Fare), 남성의 경우 나이(Age)가 중요

**구현 세부사항**:
- random_state=0으로 재현성 보장
- 10-겹 교차 검증 수행

### 장점
- 직관적이고 시각화하기 쉬움
- 특성 간 비선형 관계와 상호작용을 자동으로 포착
- 특성 스케일에 불변
- 데이터 전처리가 거의 필요 없음

### 단점
- 과적합 경향이 있음(작은 변화에도 트리 구조가 크게 변할 수 있음)
- 전역 최적화가 아닌 각 단계에서 지역 최적화 수행
- 불안정함(훈련 데이터 변화에 민감)

## 랜덤포레스트

### 이론적 배경

랜덤포레스트는 앙상블 기법의 일종으로, 여러 개의 결정트리를 생성하고 그 결과를 집계합니다. 각 트리는 다음과 같은 방식으로 다양성을 확보합니다:

1. **배깅(Bagging)**: 원본 데이터에서 무작위로 샘플을 추출하여 각 트리를 학습
2. **특성 무작위화**: 각 분할에서 전체 특성 중 무작위 부분집합만 고려

최종 예측은 다수결 투표로 결정됩니다.

### 타이타닉 데이터셋에 적용

랜덤포레스트는 79.69%의 정확도로 모든 알고리즘 중 가장 좋은 성능을 보였습니다. 이러한 성공 요인은:

- **다양한 결정트리의 집단 지성**: 여러 트리가 타이타닉 데이터의 다양한 패턴을 포착
- **과적합 감소**: 개별 트리의 과적합 경향이 앙상블을 통해 완화
- **특성 상호작용 포착**: 성별, 객실 등급, 나이 사이의 복잡한 상호작용을 학습

**구현 세부사항**:
- n_estimators=100 (100개의 결정트리 사용)
- random_state=0으로 재현성 보장
- 10-겹 교차 검증 수행

### 장점
- 높은 예측 정확도
- 과적합에 강함
- 대규모 데이터와 고차원 특성에 효과적
- 특성 중요도 평가 가능

### 단점
- 계산 비용이 높음(다수의 트리 생성 및 예측 필요)
- 해석이 결정트리보다 어려움
- 메모리 사용량이 많음

## SVM (Support Vector Machine)

### 이론적 배경

서포트 벡터 머신(SVM)은 클래스를 분리하는 최적의 초평면(hyperplane)을 찾는 것을 목표로 합니다. 이 초평면은 두 클래스 간의 마진(여백)을 최대화하는 방향으로 결정됩니다.

수학적으로 SVM은 다음 최적화 문제를 해결합니다:
$$\min_{w, b} \frac{1}{2} \|w\|^2$$
$$\text{subject to } y_i(w \cdot x_i + b) \geq 1 \text{ for all } i$$

여기서:
- $w$는 초평면의 법선 벡터
- $b$는 편향(bias)
- $x_i$는 특성 벡터, $y_i$는 클래스 레이블 (±1)

비선형 분류를 위해 커널 트릭을 사용합니다:
- **선형 커널**: $K(x, y) = x \cdot y$
- **RBF 커널**: $K(x, y) = \exp(-\gamma \|x-y\|^2)$
- **다항식 커널**: $K(x, y) = (x \cdot y + c)^d$

### 타이타닉 데이터셋에 적용

SVM은 61.62%의 정확도로 KNN보다는 좋지만 다른 알고리즘보다는 낮은 성능을 보였습니다. 이러한 결과의 원인:

- **파라미터 최적화 부족**: 기본 RBF 커널 사용, 최적의 C와 gamma 값을 찾지 못함
- **특성 스케일링 문제**: SVM은 특성 스케일에 민감하지만 Pipeline에서 처리되지 않음
- **타이타닉 데이터의 성격**: 복잡한 비선형 경계보다는 단순한 규칙(성별, 클래스 등)이 중요할 수 있음

**구현 세부사항**:
- kernel='rbf' (방사 기저 함수 커널)
- random_state=0으로 재현성 보장
- 10-겹 교차 검증 수행

### 장점
- 고차원 공간에서 효과적
- 복잡한 결정 경계 학습 가능
- 과적합에 상대적으로 강함
- 이론적으로 잘 정립됨

### 단점
- 대규모 데이터셋에서 학습 속도가 느림
- 하이퍼파라미터 최적화가 어려움
- 해석이 직관적이지 않음
- 특성 스케일에 민감

## 종합 분석 및 결론

### 알고리즘 성능 비교

타이타닉 생존자 예측 모델 성능을 종합하면:

1. **랜덤포레스트(79.69%)**: 앙상블 학습을 통해 데이터의 복잡한 패턴을 가장 잘 포착했습니다. 다양한 결정트리가 성별, 객실 등급, 나이 등의 특성을 다양한 조합으로 사용하여 정확도를 높였습니다.

2. **나이브베이즈(77.22%)**: 단순한 가정에도 불구하고 놀랍게도 좋은 성능을 보였습니다. 이는 타이타닉 생존에 영향을 미치는 주요 특성들이 어느 정도 독립적으로 작용했기 때문입니다.

3. **로지스틱 회귀(76.77%)**: 단순하지만 강력한 베이스라인을 제공했습니다. 선형 모델임에도 주요 특성(성별, 클래스)의 영향을 효과적으로 포착했습니다.

4. **결정트리(74.64%)**: 직관적인 규칙을 학습했지만, 단일 트리의 한계로 인해 랜덤포레스트보다 낮은 성능을 보였습니다.

5. **SVM(61.62%)**: 최적화되지 않은 파라미터와 복잡한 알고리즘 특성으로 인해 기대에 미치지 못했습니다.

6. **KNN(58.15%)**: 차원의 저주와 범주형 데이터의 특성으로 인해 가장 낮은 성능을 보였습니다.

### 특성 중요도

모든 알고리즘에서 일관되게 중요하게 나타난 특성은:

1. **성별(Gender)**: 여성의 생존률이 남성보다 현저히 높았습니다("여성과 어린이 먼저" 규칙)
2. **객실 등급(Pclass)**: 상위 클래스 승객의 생존률이 높았습니다
3. **나이(Age/AgeGroup)**: 어린이의 생존률이 높았습니다
4. **타이틀(Title)**: 부분적으로 성별 및 사회적 지위를 반영합니다

### 향후 개선 방향

모델 성능을 더 향상시키기 위한 방안:

1. **하이퍼파라미터 최적화**: GridSearchCV 또는 RandomizedSearchCV를 사용하여 각 알고리즘의 최적 파라미터 탐색
2. **특성 공학 강화**: 가족 크기, 객실 위치 등 추가 특성 생성
3. **앙상블 기법**: 여러 모델의 예측을 결합(보팅, 스태킹)
4. **딥러닝 적용**: 신경망을 사용하여 더 복잡한 패턴 학습

### 딥러닝으로의 확장

이 분석은 전통적인 머신러닝 알고리즘에 초점을 맞추었지만, 딥러닝 모델(MLP, CNN, 트랜스포머 등)을 통해 추가적인 성능 개선이 가능할 수 있습니다. 특히 더 많은 특성과 더 복잡한 상호작용이 있는 대규모 데이터셋에서 딥러닝의 장점이 더 두드러질 것입니다.